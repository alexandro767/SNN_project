{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##SNNTorch is a torch-module fror Spiking Neural Networks"
      ],
      "metadata": {
        "id": "lPoo-62UCcw4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnpo_j80BmDK",
        "outputId": "253f6859-1b0e-4434-df0f-4198708c0806"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_412234/3748532884.py:4: DeprecationWarning: The module snntorch.backprop will be deprecated in  a future release. Writing out your own training loop will lead to substantially faster performance.\n",
            "  from snntorch import backprop\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import backprop\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFjWaOpzBmDM"
      },
      "outputs": [],
      "source": [
        "# dataloader arguments\n",
        "batch_size = 128\n",
        "data_path = \"/tmp/data/cifar10\"\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "my50IaDvB7Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading CIFAR-10"
      ],
      "metadata": {
        "id": "WyrMhUWhB_W0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaM-JbKIBmDO",
        "outputId": "0ad5abac-47ce-4d60-8bc5-51ecdb452da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000 10000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((32, 32)),\n",
        "        # transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0,), (1,)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "cifar_train = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True, transform=transform\n",
        ")\n",
        "cifar_test = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    cifar_train, batch_size=batch_size, shuffle=True, drop_last=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    cifar_test, batch_size=batch_size, shuffle=True, drop_last=True\n",
        ")\n",
        "\n",
        "print(len(cifar_train), len(cifar_test))\n",
        "cifar_test[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define network"
      ],
      "metadata": {
        "id": "dGHfj9rSB23H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtxIaU_2BmDQ"
      },
      "outputs": [],
      "source": [
        "# neuron and simulation parameters\n",
        "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
        "beta = 0.5\n",
        "num_steps = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnfR3AjFBmDQ",
        "outputId": "02140041-735b-49f5-e833-0762c9327175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# #  Initialize Network\n",
        "learn_beta = False\n",
        "learn_threshold = False\n",
        "hidden_channels = 16\n",
        "\n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Conv2d(3, hidden_channels, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels),\n",
        "    nn.Conv2d(hidden_channels, hidden_channels, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels),\n",
        "    nn.MaxPool2d(2),\n",
        "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,\n",
        "              learn_beta=learn_beta, learn_threshold=learn_threshold),\n",
        "\n",
        "    nn.Conv2d(hidden_channels, hidden_channels*2, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels*2),\n",
        "    nn.Conv2d(hidden_channels*2, hidden_channels*2, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels*2),\n",
        "    nn.MaxPool2d(2),\n",
        "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,\n",
        "              learn_beta=learn_beta, learn_threshold=learn_threshold),  # 42% 15 epochs\n",
        "\n",
        "    nn.Conv2d(hidden_channels*2, hidden_channels*4, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels*4),\n",
        "    nn.Conv2d(hidden_channels*4, hidden_channels*4, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels*4),\n",
        "    nn.MaxPool2d(2),\n",
        "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,\n",
        "              learn_beta=learn_beta, learn_threshold=learn_threshold),  # 48.13%\n",
        "\n",
        "    nn.Conv2d(hidden_channels*4, hidden_channels*8, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels*8),\n",
        "    nn.Conv2d(hidden_channels*8, hidden_channels*8, 3, padding=\"same\"),\n",
        "    nn.BatchNorm2d(num_features=hidden_channels*8),\n",
        "    nn.MaxPool2d(2),\n",
        "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,\n",
        "              learn_beta=learn_beta, learn_threshold=learn_threshold),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(512, 10),\n",
        "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,\n",
        "              learn_beta=learn_beta, learn_threshold=learn_threshold, output=False)\n",
        ").to(device)\n",
        "\n",
        "# test input-output\n",
        "\n",
        "data, targets = next(iter(train_loader))\n",
        "print(data.shape)\n",
        "data = data.to(device)\n",
        "targets = targets.to(device)\n",
        "\n",
        "for step in range(num_steps):\n",
        "    spk_out = net(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MbSD90jBmDS",
        "outputId": "da689181-3f68-45ee-a85f-9b76d4258d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "def forward_pass(net, num_steps, data):\n",
        "    mem_rec = []\n",
        "    spk_rec = []\n",
        "    utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
        "\n",
        "    spike_data = spikegen.rate(\n",
        "        data.to(device), num_steps=num_steps, gain=0.5).to(device)\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        spk_out = net(spike_data[step].squeeze(0))\n",
        "        spk_rec.append(spk_out)\n",
        "\n",
        "    return torch.stack(spk_rec)\n",
        "\n",
        "# test input-output\n",
        "\n",
        "\n",
        "data, targets = next(iter(train_loader))\n",
        "print(data.shape)\n",
        "data = data.to(device)\n",
        "targets = targets.to(device)\n",
        "\n",
        "for step in range(num_steps):\n",
        "    spk_out = net(data)\n",
        "\n",
        "spk_rec = forward_pass(net, num_steps, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RrOi72KBmDT",
        "outputId": "1ec2da5b-0cbc-4382-ed50-f1a836317286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The loss from an untrained network is 2.304\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total accuracy on the test set is: 10.00%\n"
          ]
        }
      ],
      "source": [
        "loss_fn = SF.ce_rate_loss()\n",
        "\n",
        "loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "print(f\"The loss from an untrained network is {loss_val.item():.3f}\")\n",
        "\n",
        "acc = SF.accuracy_rate(spk_rec, targets)\n",
        "\n",
        "\n",
        "def batch_accuracy(train_loader, net, num_steps):\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        acc = 0\n",
        "        net.eval()\n",
        "\n",
        "        train_loader = iter(train_loader)\n",
        "        for data, targets in train_loader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "            spk_rec = forward_pass(net, num_steps, data)\n",
        "\n",
        "            acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "            total += spk_rec.size(1)\n",
        "\n",
        "    return acc/total\n",
        "\n",
        "\n",
        "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "\n",
        "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Schedulers"
      ],
      "metadata": {
        "id": "hOO1a37RCG-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB60OvIqBmDT",
        "outputId": "a93fb744-747e-41ca-9da0-5ab7918d42e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import copy\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_schedule(schedule_fn, iterations=500):\n",
        "    # Iteration count starting at 1\n",
        "    iterations = [i+1 for i in range(iterations)]\n",
        "    lrs = [schedule_fn(i) for i in iterations]\n",
        "    plt.scatter(iterations, lrs)\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.show()\n",
        "\n",
        "class TriangularSchedule():\n",
        "    def __init__(self, min_lr, max_lr, cycle_length, inc_fraction=0.3):\n",
        "        \"\"\"\n",
        "        min_lr: lower bound for learning rate (float)\n",
        "        max_lr: upper bound for learning rate (float)\n",
        "        cycle_length: iterations between start and finish (int)\n",
        "        inc_fraction: fraction of iterations spent in increasing stage (float)\n",
        "        \"\"\"\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.cycle_length = cycle_length\n",
        "        self.inc_fraction = inc_fraction\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        if iteration <= self.cycle_length*self.inc_fraction:\n",
        "            unit_cycle = iteration * 1 / (self.cycle_length * self.inc_fraction)\n",
        "        elif iteration <= self.cycle_length:\n",
        "            unit_cycle = (self.cycle_length - iteration) * 1 / (self.cycle_length * (1 - self.inc_fraction))\n",
        "        else:\n",
        "            unit_cycle = 0\n",
        "        adjusted_cycle = (unit_cycle * (self.max_lr - self.min_lr)) + self.min_lr\n",
        "        return adjusted_cycle\n",
        "\n",
        "\n",
        "class CyclicalSchedule():\n",
        "    def __init__(self, schedule_class, cycle_length, cycle_length_decay=1, cycle_magnitude_decay=1, **kwargs):\n",
        "        \"\"\"\n",
        "        schedule_class: class of schedule, expected to take `cycle_length` argument\n",
        "        cycle_length: iterations used for initial cycle (int)\n",
        "        cycle_length_decay: factor multiplied to cycle_length each cycle (float)\n",
        "        cycle_magnitude_decay: factor multiplied learning rate magnitudes each cycle (float)\n",
        "        kwargs: passed to the schedule_class\n",
        "        \"\"\"\n",
        "        self.schedule_class = schedule_class\n",
        "        self.length = cycle_length\n",
        "        self.length_decay = cycle_length_decay\n",
        "        self.magnitude_decay = cycle_magnitude_decay\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def __call__(self, iteration):\n",
        "        cycle_idx = 0\n",
        "        cycle_length = self.length\n",
        "        idx = self.length\n",
        "        while idx <= iteration:\n",
        "            cycle_length = math.ceil(cycle_length * self.length_decay)\n",
        "            cycle_idx += 1\n",
        "            idx += cycle_length\n",
        "        cycle_offset = iteration - idx + cycle_length\n",
        "\n",
        "        schedule = self.schedule_class(cycle_length=cycle_length, **self.kwargs)\n",
        "        return schedule(cycle_offset) * self.magnitude_decay**cycle_idx\n",
        "\n",
        "schedule = CyclicalSchedule(TriangularSchedule, min_lr=0.01, max_lr=0.1, cycle_length=100, cycle_magnitude_decay=0.5)\n",
        "plot_schedule(schedule)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tS0AcHEtCTJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "TLXxtM4ACTxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRHnqr-cBmDU",
        "outputId": "c22d85ef-befe-497e-f505-fb177a1d120e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Iteration 20096, Test Acc: 27.50%\n",
            "\n",
            "Epoch 0, Iteration 40064, Test Acc: 33.45%\n",
            "\n",
            "Epoch 1, Iteration 20096, Test Acc: 36.22%\n",
            "\n",
            "Epoch 1, Iteration 40064, Test Acc: 39.30%\n",
            "\n",
            "Epoch 2, Iteration 20096, Test Acc: 41.60%\n",
            "\n",
            "Epoch 2, Iteration 40064, Test Acc: 42.18%\n",
            "\n",
            "Epoch 3, Iteration 20096, Test Acc: 45.16%\n",
            "\n",
            "Epoch 3, Iteration 40064, Test Acc: 45.21%\n",
            "\n",
            "Epoch 4, Iteration 20096, Test Acc: 45.30%\n",
            "\n",
            "Epoch 4, Iteration 40064, Test Acc: 44.39%\n",
            "\n",
            "Epoch 5, Iteration 20096, Test Acc: 46.38%\n",
            "\n",
            "Epoch 5, Iteration 40064, Test Acc: 46.60%\n",
            "\n",
            "Epoch 6, Iteration 20096, Test Acc: 48.39%\n",
            "\n",
            "Epoch 6, Iteration 40064, Test Acc: 48.65%\n",
            "\n",
            "Epoch 7, Iteration 20096, Test Acc: 46.69%\n",
            "\n",
            "Epoch 7, Iteration 40064, Test Acc: 47.39%\n",
            "\n",
            "Epoch 8, Iteration 20096, Test Acc: 49.27%\n",
            "\n",
            "Epoch 8, Iteration 40064, Test Acc: 48.60%\n",
            "\n",
            "Epoch 9, Iteration 20096, Test Acc: 49.99%\n",
            "\n",
            "Epoch 9, Iteration 40064, Test Acc: 50.06%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.cuda.amp import GradScaler\n",
        "from tqdm import trange\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 10\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter_global = 0\n",
        "counter_local = 0\n",
        "\n",
        "\n",
        "schedule = CyclicalSchedule(\n",
        "    TriangularSchedule,\n",
        "    min_lr=0.01,\n",
        "    max_lr=0.1,\n",
        "    cycle_length=3,\n",
        "    cycle_magnitude_decay=0.7,\n",
        ")\n",
        "def lambda_schedule(iteration): return schedule(iteration)\n",
        "\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lambda_schedule)\n",
        "\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    counter_global = 0\n",
        "    counter_local = 0\n",
        "    # Training loop\n",
        "    for data, targets in iter(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec = forward_pass(net, num_steps, data)\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        if counter_local // 20000 != 0:\n",
        "            counter_local = counter_local % 20000\n",
        "            with torch.no_grad():\n",
        "                net.eval()\n",
        "\n",
        "                # Test set forward pass\n",
        "                test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "                print(\n",
        "                    f\"Epoch {epoch}, Iteration {counter_global}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
        "                test_acc_hist.append(test_acc.item())\n",
        "\n",
        "        counter_global += len(targets)\n",
        "        counter_local += len(targets)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JljlhI8eBmDV",
        "outputId": "829c70af-e2e6-4945-ee4c-f0169404858c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Iteration 20096, Test Acc: 50.36%\n",
            "\n",
            "Epoch 10, Iteration 40064, Test Acc: 50.27%\n",
            "\n",
            "Epoch 11, Iteration 20096, Test Acc: 47.56%\n",
            "\n",
            "Epoch 11, Iteration 40064, Test Acc: 46.57%\n",
            "\n",
            "Epoch 12, Iteration 20096, Test Acc: 48.72%\n",
            "\n",
            "Epoch 12, Iteration 40064, Test Acc: 49.61%\n",
            "\n",
            "Epoch 13, Iteration 20096, Test Acc: 51.02%\n",
            "\n",
            "Epoch 13, Iteration 40064, Test Acc: 50.95%\n",
            "\n",
            "Epoch 14, Iteration 20096, Test Acc: 49.78%\n",
            "\n",
            "Epoch 14, Iteration 40064, Test Acc: 48.70%\n",
            "\n",
            "Epoch 15, Iteration 20096, Test Acc: 50.69%\n",
            "\n",
            "Epoch 15, Iteration 40064, Test Acc: 51.38%\n",
            "\n",
            "Epoch 16, Iteration 20096, Test Acc: 52.33%\n",
            "\n",
            "Epoch 16, Iteration 40064, Test Acc: 52.53%\n",
            "\n",
            "Epoch 17, Iteration 20096, Test Acc: 51.18%\n",
            "\n",
            "Epoch 17, Iteration 40064, Test Acc: 50.85%\n",
            "\n",
            "Epoch 18, Iteration 20096, Test Acc: 52.61%\n",
            "\n",
            "Epoch 18, Iteration 40064, Test Acc: 53.29%\n",
            "\n",
            "Epoch 19, Iteration 20096, Test Acc: 53.19%\n",
            "\n",
            "Epoch 19, Iteration 40064, Test Acc: 53.60%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.cuda.amp import GradScaler\n",
        "from tqdm import trange\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 20\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter_global = 0\n",
        "counter_local = 0\n",
        "epoch = 10\n",
        "\n",
        "\n",
        "schedule = CyclicalSchedule(\n",
        "    TriangularSchedule,\n",
        "    min_lr=0.01,\n",
        "    max_lr=0.1,\n",
        "    cycle_length=3,\n",
        "    cycle_magnitude_decay=0.7,\n",
        ")\n",
        "def lambda_schedule(iteration): return schedule(iteration)\n",
        "\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lambda_schedule)\n",
        "\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(epoch, num_epochs):\n",
        "    counter_global = 0\n",
        "    counter_local = 0\n",
        "    # Training loop\n",
        "    for data, targets in iter(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec = forward_pass(net, num_steps, data)\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        if counter_local // 20000 != 0:\n",
        "            counter_local = counter_local % 20000\n",
        "            with torch.no_grad():\n",
        "                net.eval()\n",
        "\n",
        "                # Test set forward pass\n",
        "                test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "                print(\n",
        "                    f\"Epoch {epoch}, Iteration {counter_global}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
        "                test_acc_hist.append(test_acc.item())\n",
        "\n",
        "        counter_global += len(targets)\n",
        "        counter_local += len(targets)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RITQKEGBmDX",
        "outputId": "ff1ed091-05af-45e2-c051-4a954bdeb42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Iteration 20096, Test Acc: 54.01%\n",
            "\n",
            "Epoch 20, Iteration 40064, Test Acc: 54.05%\n",
            "\n",
            "Epoch 21, Iteration 20096, Test Acc: 50.62%\n",
            "\n",
            "Epoch 21, Iteration 40064, Test Acc: 50.12%\n",
            "\n",
            "Epoch 22, Iteration 20096, Test Acc: 52.26%\n",
            "\n",
            "Epoch 22, Iteration 40064, Test Acc: 52.78%\n",
            "\n",
            "Epoch 23, Iteration 20096, Test Acc: 53.54%\n",
            "\n",
            "Epoch 23, Iteration 40064, Test Acc: 53.98%\n",
            "\n",
            "Epoch 24, Iteration 20096, Test Acc: 51.27%\n",
            "\n",
            "Epoch 24, Iteration 40064, Test Acc: 52.70%\n",
            "\n",
            "Epoch 25, Iteration 20096, Test Acc: 53.36%\n",
            "\n",
            "Epoch 25, Iteration 40064, Test Acc: 53.66%\n",
            "\n",
            "Epoch 26, Iteration 20096, Test Acc: 54.50%\n",
            "\n",
            "Epoch 26, Iteration 40064, Test Acc: 54.57%\n",
            "\n",
            "Epoch 27, Iteration 20096, Test Acc: 53.91%\n",
            "\n",
            "Epoch 27, Iteration 40064, Test Acc: 53.06%\n",
            "\n",
            "Epoch 28, Iteration 20096, Test Acc: 54.72%\n",
            "\n",
            "Epoch 28, Iteration 40064, Test Acc: 53.48%\n",
            "\n",
            "Epoch 29, Iteration 20096, Test Acc: 54.96%\n",
            "\n",
            "Epoch 29, Iteration 40064, Test Acc: 54.77%\n",
            "\n",
            "Epoch 30, Iteration 20096, Test Acc: 54.47%\n",
            "\n",
            "Epoch 30, Iteration 40064, Test Acc: 54.42%\n",
            "\n",
            "Epoch 31, Iteration 20096, Test Acc: 54.35%\n",
            "\n",
            "Epoch 31, Iteration 40064, Test Acc: 56.05%\n",
            "\n",
            "Epoch 32, Iteration 20096, Test Acc: 56.35%\n",
            "\n",
            "Epoch 32, Iteration 40064, Test Acc: 56.29%\n",
            "\n",
            "Epoch 33, Iteration 20096, Test Acc: 55.93%\n",
            "\n",
            "Epoch 33, Iteration 40064, Test Acc: 54.93%\n",
            "\n",
            "Epoch 34, Iteration 20096, Test Acc: 56.35%\n",
            "\n",
            "Epoch 34, Iteration 40064, Test Acc: 56.25%\n",
            "\n",
            "Epoch 35, Iteration 20096, Test Acc: 56.17%\n",
            "\n",
            "Epoch 35, Iteration 40064, Test Acc: 56.52%\n",
            "\n",
            "Epoch 36, Iteration 20096, Test Acc: 56.58%\n",
            "\n",
            "Epoch 36, Iteration 40064, Test Acc: 55.75%\n",
            "\n",
            "Epoch 37, Iteration 20096, Test Acc: 56.90%\n",
            "\n",
            "Epoch 37, Iteration 40064, Test Acc: 56.68%\n",
            "\n",
            "Epoch 38, Iteration 20096, Test Acc: 56.85%\n",
            "\n",
            "Epoch 38, Iteration 40064, Test Acc: 56.00%\n",
            "\n",
            "Epoch 39, Iteration 20096, Test Acc: 56.76%\n",
            "\n",
            "Epoch 39, Iteration 40064, Test Acc: 56.46%\n",
            "\n",
            "Epoch 40, Iteration 20096, Test Acc: 56.06%\n",
            "\n",
            "Epoch 40, Iteration 40064, Test Acc: 56.04%\n",
            "\n",
            "Epoch 41, Iteration 20096, Test Acc: 56.28%\n",
            "\n",
            "Epoch 41, Iteration 40064, Test Acc: 56.86%\n",
            "\n",
            "Epoch 42, Iteration 20096, Test Acc: 56.55%\n",
            "\n",
            "Epoch 42, Iteration 40064, Test Acc: 57.11%\n",
            "\n",
            "Epoch 43, Iteration 20096, Test Acc: 56.74%\n",
            "\n",
            "Epoch 43, Iteration 40064, Test Acc: 57.36%\n",
            "\n",
            "Epoch 44, Iteration 20096, Test Acc: 56.68%\n",
            "\n",
            "Epoch 44, Iteration 40064, Test Acc: 56.53%\n",
            "\n",
            "Epoch 45, Iteration 20096, Test Acc: 56.31%\n",
            "\n",
            "Epoch 45, Iteration 40064, Test Acc: 56.72%\n",
            "\n",
            "Epoch 46, Iteration 20096, Test Acc: 57.03%\n",
            "\n",
            "Epoch 46, Iteration 40064, Test Acc: 56.93%\n",
            "\n",
            "Epoch 47, Iteration 20096, Test Acc: 56.72%\n",
            "\n",
            "Epoch 47, Iteration 40064, Test Acc: 56.89%\n",
            "\n",
            "Epoch 48, Iteration 20096, Test Acc: 56.76%\n",
            "\n",
            "Epoch 48, Iteration 40064, Test Acc: 56.97%\n",
            "\n",
            "Epoch 49, Iteration 20096, Test Acc: 56.83%\n",
            "\n",
            "Epoch 49, Iteration 40064, Test Acc: 57.22%\n",
            "\n",
            "Epoch 50, Iteration 20096, Test Acc: 57.21%\n",
            "\n",
            "Epoch 50, Iteration 40064, Test Acc: 57.14%\n",
            "\n",
            "Epoch 51, Iteration 20096, Test Acc: 56.79%\n",
            "\n",
            "Epoch 51, Iteration 40064, Test Acc: 57.11%\n",
            "\n",
            "Epoch 52, Iteration 20096, Test Acc: 57.23%\n",
            "\n",
            "Epoch 52, Iteration 40064, Test Acc: 57.12%\n",
            "\n",
            "Epoch 53, Iteration 20096, Test Acc: 57.19%\n",
            "\n",
            "Epoch 53, Iteration 40064, Test Acc: 57.16%\n",
            "\n",
            "Epoch 54, Iteration 20096, Test Acc: 57.13%\n",
            "\n",
            "Epoch 54, Iteration 40064, Test Acc: 56.94%\n",
            "\n",
            "Epoch 55, Iteration 20096, Test Acc: 57.14%\n",
            "\n",
            "Epoch 55, Iteration 40064, Test Acc: 57.53%\n",
            "\n",
            "Epoch 56, Iteration 20096, Test Acc: 57.63%\n",
            "\n",
            "Epoch 56, Iteration 40064, Test Acc: 57.35%\n",
            "\n",
            "Epoch 57, Iteration 20096, Test Acc: 57.72%\n",
            "\n",
            "Epoch 57, Iteration 40064, Test Acc: 57.68%\n",
            "\n",
            "Epoch 58, Iteration 20096, Test Acc: 57.54%\n",
            "\n",
            "Epoch 58, Iteration 40064, Test Acc: 57.43%\n",
            "\n",
            "Epoch 59, Iteration 20096, Test Acc: 57.44%\n",
            "\n",
            "Epoch 59, Iteration 40064, Test Acc: 57.38%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.cuda.amp import GradScaler\n",
        "from tqdm import trange\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 60\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter_global = 0\n",
        "counter_local = 0\n",
        "epoch = 20\n",
        "\n",
        "\n",
        "schedule = CyclicalSchedule(\n",
        "    TriangularSchedule,\n",
        "    min_lr=0.01,\n",
        "    max_lr=0.1,\n",
        "    cycle_length=3,\n",
        "    cycle_magnitude_decay=0.7,\n",
        ")\n",
        "def lambda_schedule(iteration): return schedule(iteration)\n",
        "\n",
        "\n",
        "scheduler = LambdaLR(optimizer, lr_lambda=lambda_schedule)\n",
        "\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(epoch, num_epochs):\n",
        "    counter_global = 0\n",
        "    counter_local = 0\n",
        "    # Training loop\n",
        "    for data, targets in iter(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec = forward_pass(net, num_steps, data)\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        if counter_local // 20000 != 0:\n",
        "            counter_local = counter_local % 20000\n",
        "            with torch.no_grad():\n",
        "                net.eval()\n",
        "\n",
        "                # Test set forward pass\n",
        "                test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "                print(\n",
        "                    f\"Epoch {epoch}, Iteration {counter_global}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
        "                test_acc_hist.append(test_acc.item())\n",
        "\n",
        "        counter_global += len(targets)\n",
        "        counter_local += len(targets)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "muZlJ1fNCX8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfocPNyMBmDY",
        "outputId": "7d3e0951-3f11-44a1-ca04-5da0c5beef02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total accuracy on the test set is: 57.26%\n"
          ]
        }
      ],
      "source": [
        "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "\n",
        "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctxPKkwsBmDY",
        "outputId": "dfd7c4b4-20e4-4625-b389-39b6120c68d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7952400384\n",
            "_CudaDeviceProperties(name='NVIDIA L4', major=8, minor=9, total_memory=22699MB, multi_processor_count=58)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.3319636861298796"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import gc\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "DEVICE = \"cuda\"\n",
        "\n",
        "\n",
        "def cache_clear():  # In colab to clear GPU cache you need to wait some time after deleting tensor\n",
        "    if COLAB:\n",
        "        time.sleep(0.08)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def gpu_util():  # To monitor how much more can we load GPU with data\n",
        "    if DEVICE == \"cuda\":\n",
        "        return (\n",
        "            torch.cuda.memory_allocated(DEVICE)\n",
        "            / torch.cuda.get_device_properties(DEVICE).total_memory\n",
        "        )\n",
        "    if DEVICE == \"cpu\":\n",
        "        return 0\n",
        "\n",
        "\n",
        "cache_clear()\n",
        "print(torch.cuda.memory_reserved(DEVICE))\n",
        "print(torch.cuda.get_device_properties(DEVICE))\n",
        "\n",
        "gc.collect()\n",
        "gpu_util()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}